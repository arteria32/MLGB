{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 4. Деревья решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaYHywS6JQb4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOCTpPF3f9TW"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 500.  700.  750.  600. 1450.  800. 1500. 2000.  450. 1000.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "[False False False False  True False  True  True False  True]\n",
      "[1. 1. 0. 1.]\n",
      "Нулей: 1 единиц: 3\n"
     ]
    }
   ],
   "source": [
    "# проба задания порога t = 1000\n",
    "x = X[2,:]\n",
    "print(x)\n",
    "print(y)\n",
    "print(x >= 1000)\n",
    "print(y[x >= 1000])\n",
    "right_1 = (y[x >= 1000] == 0)\n",
    "right_2 = (y[x >= 1000] == 1)\n",
    "print('Нулей:', right_1.sum(), 'единиц:', right_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _Критерий Джини_ или _индекс Джини_ выглядит следующим образом:\n",
    "\n",
    "$$H(X) = \\sum^{K}_{k=1}p_{k}(1-p_{k}),$$\n",
    "\n",
    "где $K$ - количество классов в наборе данных $X$.\n",
    "\n",
    "Его минимум достигается когда все объекты в подмножестве относятся к одному классу, а максимум - при равном содержании объектов всех класов. Критерий информативности Джини можно интерпретировать как вероятность ошибки случайного классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индекс Джини для левого листа\n",
    "# h_left = p0_left * (1 - p0_left) + p1_left * (1 - p1_left)\n",
    "# Индекс Джини для правого листа\n",
    "# h_right = p0_right * (1 - p0_right) + p1_right * (1 - p1_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{|X_{l}|}{|X_{m}|}H(X_{l}) - \\frac{|X_{r}|}{|X_{m}|}H(X_{r}),$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = left_coef * h_left + (1 - left_coef) * h_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vsdBwOgXBIJ"
   },
   "outputs": [],
   "source": [
    "# считаем информативность разбиения\n",
    "def calc_gini(x, y, t):z\n",
    "    qty_all = len(y) # объектов всего\n",
    "    qty_left = len(y[x < t]) # объектов в левой ветке\n",
    "    qty_right = qty_all - qty_left  # объектов в правой ветке\n",
    "\n",
    "    # Начальное приближение индекса Джини. Индекс Джини не будет равен бесконечности в таком случае,\n",
    "    # но и считать его особо смысла нет, т.к. получается только одна ветвь\n",
    "    if qty_left == 0 or qty_right == 0:\n",
    "        return np.inf\n",
    "\n",
    "    qty0_left = ((y[x < t]) == 0).sum() \n",
    "    qty0_right = ((y[x >= t]) == 0).sum()\n",
    "\n",
    "    p0_left = qty0_left / qty_left # Доля объектов класса 0 слева\n",
    "    p1_left = 1 - p0_left # Доля объектов класса 1 слева\n",
    "\n",
    "    p0_right = qty0_right / qty_right  # Доля объектов класса 0 справа\n",
    "    p1_right = 1 - p0_right # Доля объектов класса 1 справа\n",
    "\n",
    "    # Нормировочный коэффициент для левого листа\n",
    "    left_coef = qty_left / qty_all\n",
    "\n",
    "    # Индекс Джини для левого листа\n",
    "    h_left = p0_left * (1 - p0_left) + p1_left * (1 - p1_left)\n",
    "    # Индекс Джини для правого листа\n",
    "    h_right = p0_right * (1 - p0_right) + p1_right * (1 - p1_right)\n",
    "\n",
    "    res = left_coef * h_left + (1 - left_coef) * h_right\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции оценки качества разбиения используется критерий Джини, который также может быть записан как\n",
    "\n",
    "$$H(X) = 1 - \\sum^{K}_{k=1}p_{k}^{2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBdli3WDabXn"
   },
   "outputs": [],
   "source": [
    "# Расчет критерия Джини\n",
    "\n",
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "        \n",
    "    return impurity, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1.]\n",
      "0.375 {1.0: 3, 0.0: 1}\n",
      "[0. 0. 1. 0. 0. 1.]\n",
      "0.4444444444444445 {0.0: 4, 1.0: 2}\n"
     ]
    }
   ],
   "source": [
    "print(y[x >= 1000])\n",
    "i, c = gini(y[x >= 1000])\n",
    "print(i, c)\n",
    "\n",
    "print(y[x < 1000])\n",
    "i, c = gini(y[x < 1000])\n",
    "print(i, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерий Джини - его минимум достигается когда все объекты в подмножестве относятся к одному классу, а максимум - при равном содержании объектов всех класов. Критерий информативности Джини можно интерпретировать как вероятность ошибки случайного классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Критерий Джини_ 2ой вариант вычисления:\n",
    "\n",
    "$$H(X) = \\sum^{K}_{k=1}p_{k}(1-p_{k}),$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dJs7ovMY1E-"
   },
   "outputs": [],
   "source": [
    "# Расчет прироста качества (при разбиении вершины дерева)\n",
    "\n",
    "def quality_0(left_labels, right_labels):\n",
    "\n",
    "    # доля выбоки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    gini_left, _ = gini(left_labels)\n",
    "    gini_right, _ = gini(right_labels)\n",
    "    \n",
    "    return p * gini_left + (1 - p) * gini_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "3Ybn5PI-gILB",
    "outputId": "03a8dbab-d45e-4aa6-c642-6b6994438ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог: 500.0, gini = 0.4444444444444444 (0.4444444444444444)\n",
      "Порог: 700.0, gini = 0.47619047619047616 (0.47619047619047616)\n",
      "Порог: 750.0, gini = 0.4166666666666667 (0.4166666666666667)\n",
      "Порог: 600.0, gini = 0.5 (0.5)\n",
      "Порог: 1450.0, gini = 0.47619047619047616 (0.4761904761904763)\n",
      "Порог: 800.0, gini = 0.48 (0.48)\n",
      "Порог: 1500.0, gini = 0.5 (0.5)\n",
      "Порог: 2000.0, gini = 0.4444444444444444 (0.4444444444444444)\n",
      "Порог: 450.0, gini = inf (0.5)\n",
      "Порог: 1000.0, gini = 0.4166666666666667 (0.4166666666666667)\n"
     ]
    }
   ],
   "source": [
    "for t in x:\n",
    "    print('Порог: {}, gini = {} ({})'.format(t, calc_gini(x, y, t), quality_0(y[x < t], y[x >= t])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание**\n",
    "\n",
    "1. В коде из методички реализуйте один или несколько из критериев останова (количество листьев, количество используемых признаков, глубина дерева и т.д.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "2*.  Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений.\n",
    "В материалах также есть пример скрипта для расчета дерева - Lesson_4_script, им можно воспользоваться аналогично тому, как это было на предыдущих уроках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Останов в случае, когда все объекты в листе относятся к одному классу.\n",
    "def find_best_split(data, labels):\n",
    "    current_gini = gini(labels) \n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None # лучший порог разбиения\n",
    "    best_index = None # лучший индекс разбиения\n",
    "    \n",
    "    n_features = data.shape[1] # кол-во признаков\n",
    "    \n",
    "    for index in range(n_features): # проход по всем признакам\n",
    "        t_values = [row[index] for row in data] # берем столбец/признак с соотв. индексом\n",
    "        \n",
    "        for t in t_values: # проход по признаку\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t) # делаем разбиение\n",
    "            # Проверка на случай, когда все объекты в листе относятся к одному классу\n",
    "            if len(true_data)==0 or len(false_data)==0:\n",
    "                break # Выходим из цикла\n",
    "            \n",
    "            # расчет качества текущего разбиения\n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность уменьшилась до 96.67%  в силу небольшого переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена механизма предсказания в листе на взятие среднего значения по выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "classification_data, classification_labels = datasets.make_classification(n_features = 2, n_informative = 2, \n",
    "                                                      n_classes = 2, n_redundant=0, \n",
    "                                                      n_clusters_per_class=1, random_state=5)\n",
    "# Реализуем класс узла\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "        \n",
    "        \n",
    "# И класс терминального узла (листа)\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data # значения признаков\n",
    "        self.labels = labels  # y_true\n",
    "        self.average = self.average()  # y_pred\n",
    "    def average(self):\n",
    "        for item in self.data:\n",
    "            k+=1\n",
    "            avg+=item\n",
    "        avg=avg/k\n",
    "        return avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замена критерия Джини на дисперсию значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp(avg, self):\n",
    "    for item in self.data:\n",
    "        k+=1\n",
    "        disp+=(item-avg)^2\n",
    "    disp=disp/k\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(left_labels, right_labels, current_gini):\n",
    "\n",
    "    # доля выборки, ушедшей в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0]) # для правого (1-p)\n",
    "    \n",
    "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels) # Функционал качества\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "# Нахождение наилучшего разбиения\n",
    "\n",
    "def find_best_split(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_leaf = 5\n",
    "\n",
    "    current_disp = disp(avg, self) \n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None # лучший порог разбиения\n",
    "    best_index = None # лучший индекс разбиения\n",
    "    \n",
    "    n_features = data.shape[1] # кол-во признаков\n",
    "    \n",
    "    for index in range(n_features): # проход по всем признакам\n",
    "        t_values = [row[index] for row in data] # берем столбец/признак с соотв. индексом\n",
    "        \n",
    "        for t in t_values: # проход по признаку\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t) # делаем разбиение\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data)==0 or len(false_data)==0:\n",
    "                break # начинаем следующий проход цикла, минуя оставшееся тело цикла\n",
    "            \n",
    "            # расчет качества текущего разбиения\n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "\n",
    "def build_tree(data, labels):\n",
    "\n",
    "    quality, t, index = find_best_split(data, labels) # ищем лучшее разбиение\n",
    "#     print(quality, t, index)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    # неопределенность после разбиения осталась такой же как до\n",
    "    if quality == 0: # критерий останова\n",
    "#         print('leaf')\n",
    "        return Leaf(data, labels) \n",
    "\n",
    "    # если качество улучшилось, то делим дерево по лучшему разбиению\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_labels)\n",
    "    false_branch = build_tree(false_data, false_labels)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "# Проход объекта по дереву для его классификации\n",
    "\n",
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf): # проверка текущий узел это лист?\n",
    "        answer = node.prediction # считаем прогноз для листа\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t: # если значение признака меньше порога t\n",
    "        return classify_object(obj, node.true_branch) # рекурсия: отправляем объект в true-ветку\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch) # рекурсия: отправляем объект в false-ветку\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
